---
title: Invited Speakers
layout: single
excerpt: "AIST-2021 Invited Speakers."
permalink: /program/invited/
sidebar: 
    nav: program
---

The following speakers have graciously accepted to give keynotes at AIST-2021.<br>

## Jeremy Barnes

<figure>
  <a href="https://jerbarnes.github.io/"><img width="300" src="https://www.mn.uio.no/ifi/english/people/aca/jeremycb/jeremycb.jpg"></a>
  <figcaption><strong><a href="https://www.unive.it/pag/18669/?tx_news_pi1%5Bnews%5D=1514&cHash=6fb2d08f42d9112b0d582cca08db515f">Jeremy Barnes</a></strong> is an Assistant Professor of Natural Language Processing in IXA Group, part of the HiTZ Centre of the University of the Basque Country UPV/EHU. His research focuses on creating resources and NLP models for under-resourced languages and scenarios, including cross-lingual methods, weak supervision, multi-task learning, and domain adaptation. He has worked extensively on sentiment and emotion analysis.</figcaption>
</figure>

<b>Is it time to move beyond sentence classification?</b> <br/> <br/>
<b>Abstract:</b> Many NLP tasks (sentiment analysis, natural language understanding, etc.) are commonly cast as binary or ternary sentence classification tasks. This framing allows for quick (often semi-automated) annotation, allowing for large amounts of annotated data at sentence-level, which has made these datasets common baselines for deep learning models. Recently, performance on many of these datasets reached human-level performance, which seemed quite promising for NLP. However, it seems that many gains in performance do not lead to models that generalize well and often overfit to spurious correlations in the dataset. In this talk, I will detail a set of problems with sentence classification tasks, how they have been affected by BERT-like models, and possible solutions.

## Zulfat Miftakhutdinov

<figure>
  <a href="https://scholar.google.ru/citations?user=cL4eju0AAAAJ&hl=ru"><img width="300" src=""></a>
  <figcaption><strong><a href="https://www.unive.it/pag/18669/?tx_news_pi1%5Bnews%5D=1514&cHash=6fb2d08f42d9112b0d582cca08db515f">Zulfat Miftakhutdinov</a></strong> is a researcher in Natural Language Processing domain at Kazan Federal University. His research focuses on a medical concept normalization task and its relation to current research in natural language processing (NLP). This task aims to extract medical concepts in real conditions: given a set of documents, a system has to find biomedical entity mentions in a free-form text and map them to a certain medical concept (disease, drug, adverse drug reaction, etc.).</figcaption>
</figure>

<b>Drug and Disease Interpretation Learning with Biomedical Entity Representation Transformer</b> <br/> <br/>
<b>Abstract:</b> to be updated later.

## Irina Nikishina

<figure>
  <a href="https://crei.skoltech.ru/cdise/people/irinanikishina"><img width="300" src="/assets/images/nikishina.jpg"></a>
  <figcaption><strong><a href="https://www.unive.it/pag/18669/?tx_news_pi1%5Bnews%5D=1514&cHash=6fb2d08f42d9112b0d582cca08db515f">Irina Nikishina</a></strong> is a PhD student and NLP researcher in Skolkovo Natural Language Processing group at Skolkovo Institute of Science and Technology.</figcaption>
</figure>

<b>Taxonomy Enrichment with Text and Graph Vector Representation</b> <br/> <br/>
<b>Abstract:</b> to be updated later.
