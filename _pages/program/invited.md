---
title: Invited Speakers
layout: single
excerpt: "AIST-2020 Invited Speakers."
permalink: /program/invited/
sidebar: 
    nav: program
---

The following speakers have graciously accepted to give keynotes at AIST-2020.

## Marcello Pelillo 

<figure>
  <a href="https://www.unive.it/pag/18669/?tx_news_pi1%5Bnews%5D=1514&cHash=6fb2d08f42d9112b0d582cca08db515f"><img src="/assets/images/keynotes/pelillo.png"></a>
  <figcaption><strong><a href="https://www.unive.it/pag/18669/?tx_news_pi1%5Bnews%5D=1514&cHash=6fb2d08f42d9112b0d582cca08db515f">Marcello Pelillo</a></strong> is a Full Professor of Computer Science at Ca’ Foscari University of Venice, Italy, where he leads the Computer Vision and Pattern Recognition group. He has directed the European Centre for Living Technology (ECLT) and has held visiting research/teaching positions in various institutions such as Yale University, McGill University, the University of Vienna, York University (UK), National ICT Australia (NICTA), Wuhan University, Huazhong University of Science and Technology, and South China University of Technology. He has been General Chair for ICCV 2017, Program Chair for ICPR 2020, and has served in various roles in the organization of the main conferences of his research areas. He is the Specialty Chief Editor of Frontiers in Computer Vision and serves, or has served, on the Editorial Boards of several journals, including IEEE Transactions on Pattern Analysis and Machine Intelligence, IET Computer Vision, Pattern Recognition, and Brain Informatics. He also serves on the Advisory Board of the International Journal of Machine Learning and Cybernetics. Prof. Pelillo has been elected a Fellow of the IEEE and a Fellow of the IAPR, and is an IEEE SMC Distinguished Lecturer. His Erdös number is 2.</figcaption>
</figure>
<b>Graph-theoretic Methods in Computer Vision: Recent Advances</b> <br/> <br/>
<b>Abstract:</b> Graphs and graph-based representations have long been an important tool in computer vision and pattern recognition, especially because of their representational power and flexibility. There is now a renewed interest toward explicitly formulating computer vision problems as graph problems. This is particularly advantageous because it allows vision problems to be cast in a pure, abstract setting with solid theoretical underpinnings and also permits access to the full arsenal of graph algorithms developed in computer science and operations research. In this talk I’ll describe some recent developments in graph-theoretic methods which allow us to address within a unified and principled framework a number of classical computer vision problems. These include interactive image segmentation, image geo-localization, image retrieval, multi-camera tracking, and person re-identification. The concepts discussed here have intriguing connections with optimization theory, game theory and dynamical systems theory, and can be applied to weighted graphs, digraphs and hypergraphs alike.

## Nikita Semenov

MTS AI

<b>Text and speech processing projects at MTS AI</b> <br/> <br/>


## Santo Fortunato

Indiana University


## Miguel Couceiro 

<figure>
  <a href="https://members.loria.fr/mcouceiro/"><img width="300" src="https://members.loria.fr/mcouceiro/wp-content/blogs.dir/37/files/sites/37/2016/12/IMG_9466-1.jpg"></a>
  <figcaption><strong><a href="https://members.loria.fr/mcouceiro/">Miguel Couceiro</a></strong> is a Professor of Computer Science at University of Lorraine in Nancy, and head of the ORPAILLEUR team, LORIA (UMR 7503). His current research focuses on knowledge discovery and multicriteria decision making and, recently, with a particular emphasis on fair and explainable models. He has (co-)authored more than 180 papers and book chapters. He is an elected member (2018-2020) of IEEE CS Technical Committee on MVL, and a PC member of several conferences. He is the local coordinator of the European Erasmus Mundus master's program LCT (<a href="https://lct-master.org/">Languaguage and communication Technologies</a>) and is the responsible of the 2nd year master's program NLP at the <a href="http://institut-sciences-digitales.fr/idmc-master-degree-in-natural-language-processing/">University of Lorraine</a>.</figcaption>
</figure>
<b>Making models fairer through explanations</b> <br/> <br/>
<b>Abstract:</b> Algorithmic decisions are now being used on a daily basis, and based on Machine Learning (ML) processes that may be complex and biased. This raises several concerns given the critical impact that biased decisions may have on individuals or on society as a whole. Not only unfair outcomes affect human rights, they also undermine public trust in ML and AI.

 In this talk we will address fairness issues of ML models based on decision outcomes, and we will show how the simple idea of "feature dropout" followed by an "ensemble approach" can improve model fairness. To illustrate we will revisit the case of "LimeOut" that was proposed to tackle "process fairness", which measures a model's reliance on sensitive or discriminatory features. Given a classifier, a dataset and a set of sensitive features,  LimeOut first assesses whether the classifier is fair by checking its reliance on sensitive features using "Lime explanations". If deemed unfair, LimeOut then applies feature dropout to obtain a pool of classifiers. These are then combined into an ensemble classifier that was empirically shown to be less dependent on sensitive features without compromising the classifier's accuracy.
 
 We will present different experiments on multiple datasets and several state of the art classifiers, which show that LimeOut's classifiers improve (or at least maintain) on process fairness as well as on other fairness metrics, such as individual and group fairness, equal opportunity and demographic parity, among others.



## Leonard Kwuida
<figure>
  <a href="https://www.bfh.ch/en/about-bfh/people/c2jbrzzkbu5m/"><img width="300" src="/assets/images/keynotes/kwiudadlm.jpg"></a>
  <figcaption><strong><a href="https://www.bfh.ch/en/about-bfh/people/c2jbrzzkbu5m/">Leonard Kwuida</a></strong> graduated from Université de Yaoundé I, in Mathematics. He holds a Ph.D from TU Dresden, in Algebra and Logic. His research interest includes Formal Concept Analysis and Data Analysis, algebraic operators for knowledge discovery in databases, explainable AI, ordered structures and weak types of negation. Dr. Kwuida teaches at Bern University of Applied Sciences, School of Business.</figcaption>
</figure>
<b>Making models fairer through explanations</b> <br/> <br/>
<b>Abstract:</b> Machine Learning (ML) provides important techniques for classification and predictions. Most of these are black box models for users and do not provide decision makers with an explanation. For the sake of transparency or more validity of decisions, the need to develop explainable/interpretable ML-methods is gaining more and more importance. Certain questions need to be addressed: 
<ul>
<li>How does a ML procedure derive the class for a particular entity?</li>
<li>item Why does a particular clustering emerge from a particular unsupervised ML procedure?</li>
<li>What can we do if the number of attributes is very large?</li>
<li>What are the possible reasons of the mistakes for concrete cases and models?</li>
</ul>
For binary attributes, Formal Concept Analysis (FCA) offers techniques in terms of intents of formal concepts, and thus provides plausible reasons for model prediction. However, from the  interpretable machine learning viewpoint, we still need to provide decision makers with the importance of individual attributes to classification of a particular object, which may facilitate explanations by experts in various domains with high-cost errors like medicine or finance. 

In this talk, we will discuss how notions from cooperative game theory can be used to assess the contribution of individual attributes in classification and clustering processes in concept-based machine learning. To address the 3rd question, we present some ideas how to reduce the number of attributes using similarities in large contexts. 






