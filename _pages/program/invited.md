---
title: Invited Speakers
layout: single
excerpt: "AIST-2023 Invited Speakers."
permalink: /program/invited/
sidebar: 
    nav: program
---

The following speakers have graciously accepted to give keynotes at AIST-2023.<br>

 
## Samuel Horvath

<figure>
  <a href="https://mbzuai.ac.ae/study/faculty/samuel-horvath/"><img width="200" src="/assets/images/sam_headshot.jpeg"></a>
  <figcaption><strong><a href="https://mbzuai.ac.ae/study/faculty/samuel-horvath/">Samuel Horvath</a></strong> is an assistant professor of Machine Learning at Mohamed bin Zayed University of Artificial Intelligence (MBZUAI). Before joining MBZUAI, he completed his MS and Ph.D. in statistics at King Abdullah University of Science and Technology (KAUST) advised by Professor Peter Richtárik. Earlier in his academic journey, Samuel was an undergraduate student in Financial Mathematics at Comenius University.
In his research, Samuel focuses on providing a fundamental understanding of how distributed and federated training algorithms function and their interactions with various sources of heterogeneity. These sources include system-level computing infrastructure variability and training data statistical variability. Driven by these theoretical insights, Samuel aims to create efficient and practical distributed and federated training algorithms.
Samuel's broad interests lie in distributed, collaborative, and efficient on-device ML.
</figcaption>
</figure>

<b>Towards Real-World Federated Learning: Addressing Client Heterogeneity and Model Size</b> <br/> <br/>
<b>Abstract:</b> In this talk, I will introduce federated learning and discuss two recent approaches for addressing the challenges of client heterogeneity and model size in federated learning.
In the first part of the talk, I will introduce federated learning. I will discuss the motivation for federated learning, the key challenges, and some of the existing approaches.
In the second part of the talk, I will discuss the FjORD framework. FjORD is a framework for addressing the problem of client heterogeneity in federated learning. FjORD uses Ordered Dropout to gradually prune the model width without retraining, enabling clients with different capabilities to participate by tailoring the model width to the client's capabilities.
In the third part of the talk, I will discuss the Maestro framework. Maestro is a framework for addressing the problem of model size in federated learning. Maestro uses a technique called trainable low-rank layers to compress the model without sacrificing accuracy.
I will conclude the talk by discussing the future of federated learning.

## Hakim Hacid
<figure>
  <a href="https://scholar.google.ae/citations?user=62FX_zEAAAAJ&hl=en"><img width="200" src="/assets/images/hakim.jpg"></a>
  <figcaption><strong><a href="https://scholar.google.ae/citations?user=62FX_zEAAAAJ&hl=en">Hakim Hacid</a></strong> is the principal researcher at the AI cross-centre unit at the Technology Innovation Institute (TII), a leading scientific research centre based in the United Arab Emirates as well as an Honorary Professor at Macquarie University in Sydney, Australia. Prior to joining TII, he was an associate professor at Zayed University and contributed to research in the areas of data analysis, information retrieval and security. He also served as chairman of the Department of Computer Science and Applied Technology. Dr. Hacid has authored over 60 research papers published in leading journals and conferences and holds several industrial patents. His research interests include databases, data mining and analysis, programming, web information systems, natural language processing and security. Hakim Hacid received his PhD in data mining/databases from the University of Lyon, France. He also obtained a double master's degree in computer science (research and professional master's) from the same university.</figcaption>
</figure>

<b>Towards Edge AI: Principles, current state, and perspectives</b> <br/> <br/>
<b>Abstract:</b> The artificial intelligence (AI) community has invested heavily in developing techniques that can digest very large amounts of data to extract valuable information and knowledge. Most techniques, particularly deep learning models, require large amounts of computing and storage power, making them suitable for cloud-based environments. The intelligence is therefore remote from the end user, raising concerns about, for example, data privacy and latency. Edge AI addresses some of the problems inherent in the cloud and focuses on best practices, architectures and processes for extending data AI outside the cloud. Edge AI brings AI closer to the end user and uses, for example, fewer communication resources, as processing is performed directly on the edge device. This presentation will introduce edge AI and give an overview of existing work and potential future contributions.

<!--
## Irina Nikishina

<figure>
  <a href="https://crei.skoltech.ru/cdise/people/irinanikishina"><img width="300" src="/assets/images/nikishina.jpg"></a>
  <figcaption><strong><a href="https://crei.skoltech.ru/cdise/people/irinanikishina">Irina Nikishina</a></strong> is a PhD student and a NLP researcher in Skolkovo Natural Language Processing group at Skolkovo Institute of Science and Technology. Her research focuses on semantics and taxonomy enrichment. She also worked on entity linking and detoxification. She is also the AIST secretary and one of the founders of the semantic search engine for papers presented in Russian NLP conferences (<a href="https://nlp.rusvectores.org/en/">RusNLP</a>).</figcaption>
</figure>

<b>Taxonomy Enrichment with Text and Graph Vector Representation</b> <br/> <br/>
<b>Abstract:</b> Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a taxonomic backbone that allows the arrangement and structuring of various concepts in accordance with hypo-hypernym (``class-subclass'') relationship. With the rapid growth of lexical resources for specific domains, the problem of automatic extension of the existing knowledge bases with new words is becoming more and more widespread. In this talk, she addresses the problem of taxonomy enrichment which aims at adding new words to the existing taxonomy.

The author presents a new method which allows achieving high results on this task with little effort. It uses the resources which exist for the majority of languages, making the method universal. The method is extended by incorporating deep representations of graph structures like node2vec, Poincaré embeddings, GCN  etc. that have recently demonstrated promising results on various NLP tasks. Furthermore, combining these representations with word embeddings allows them to beat the state of the art. -->
